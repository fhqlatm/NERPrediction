{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d53413b",
   "metadata": {},
   "source": [
    "**TXT to Json String**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d44302d-c2fa-4058-90e1-166dbf57947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54e88a56-fa0b-4c15-9e4b-b95ad1f3fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_dir = '../data/ko_ner_data'\n",
    "file_name_ko_train = 'train.txt'\n",
    "file_name_ko_test = 'test.txt'\n",
    "file_name_ko_dev = 'dev.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5be12c8a-2076-4782-9a1a-bb4fec669347",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = file_name_ko_dev\n",
    "PATH_data = os.path.join(PATH_dir, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6df2a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('[IB]-[a-zA-Z]+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b80fcb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(PATH_data, 'r') as f:\n",
    "\t\n",
    "\tfdata = f.read().split('\\n\\n')\n",
    "\tdata = []\n",
    "\n",
    "\tfor sentences in fdata[:-1]:\n",
    "\n",
    "\t\tsdata = []\n",
    "\n",
    "\t\tmorph_sent = \"\"\n",
    "\t\tword_list = []\n",
    "\t\tner_list = []\n",
    "\n",
    "\t\tsentence = sentences.split('\\n')\n",
    "\t\t\n",
    "\t\tif sentence[-1] == \"\":\n",
    "\t\t\tsentence.pop()\n",
    "\n",
    "\t\tfor line in sentence:\n",
    "\t\t\tcomponents = line.split('\\t')\n",
    "\t\t\tword = components[0].split(\"/\")[0]\n",
    "\n",
    "\t\t\tif not (re.match(pattern, components[-1]) or components[-1] == 'O'):\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tmorph_sent += word + \" \"\n",
    "\t\t\tword_list.append(word)\n",
    "\t\t\tner_list.append(components[-1])\n",
    "\t\t\n",
    "\t\tmorph_sent = morph_sent[:-1]\n",
    "\n",
    "\t\tsdata.append(morph_sent)\n",
    "\t\tsdata.append(word_list)\n",
    "\t\tsdata.append(ner_list)\n",
    "\t\t\n",
    "\t\tdata.append(sdata)\n",
    "\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c2e3f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morph_sent\n",
      "선방 한 정성룡 이 볼 을 걷 어 내 고 있 다 .\n",
      "words\n",
      "['선방', '한', '정성룡', '이', '볼', '을', '걷', '어', '내', '고', '있', '다', '.']\n",
      "ner\n",
      "['O', 'O', 'B-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "morph_sent\n",
      "김학범 감독 이 장학영 에게 작전 지시 를 하 고 있 다 .\n",
      "words\n",
      "['김학범', '감독', '이', '장학영', '에게', '작전', '지시', '를', '하', '고', '있', '다', '.']\n",
      "ner\n",
      "['B-PS', 'O', 'O', 'B-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "morph_sent\n",
      "또 박지성 은 지난 달 16 일 더비 카운티전 이후 4 경기 만 에 프리미어리그 경기 에 출장 , 지난 달 2 일 풀럼전 골 포함 시즌 두 번 째 공격 포인트 를 기록 했 다 .\n",
      "words\n",
      "['또', '박지성', '은', '지난', '달', '16', '일', '더비', '카운티전', '이후', '4', '경기', '만', '에', '프리미어리그', '경기', '에', '출장', ',', '지난', '달', '2', '일', '풀럼전', '골', '포함', '시즌', '두', '번', '째', '공격', '포인트', '를', '기록', '했', '다', '.']\n",
      "ner\n",
      "['O', 'B-PS', 'O', 'B-DT', 'I-DT', 'I-DT', 'I-DT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OG', 'O', 'O', 'O', 'O', 'B-DT', 'I-DT', 'I-DT', 'I-DT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for sdata in data[:3]:\n",
    "\tprint(\"morph_sent\", sdata[0], \"words\", sdata[1], \"ner\", sdata[2], sep = '\\n', end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7fe9eb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55b87fde",
   "metadata": {},
   "source": [
    "**Tokenizing Json String**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b4dd361",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "26367abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETAINED_MODEL_NAME = 'bert-base-multilingual-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8259480",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprodata = []\n",
    "\n",
    "for sdata in data:\n",
    "\tmorph_to_tokens = tokenizer.tokenize(sdata[0])\n",
    "\n",
    "\tprepro_sdata = []\n",
    "\ttokenized_ner_list = []\n",
    "\titerated_word = iter(sdata[1])\n",
    "\titerated_ner = iter(sdata[2])\n",
    "\n",
    "\tword = \"\"\n",
    "\tentire_word = next(iterated_word)\n",
    "\tner = next(iterated_ner)\n",
    "\ttokenized_ner_list.append(ner)\n",
    "\n",
    "\tfor token in morph_to_tokens:\n",
    "\n",
    "\t\tif token[:2] == \"##\":\n",
    "\t\t\tword += token[2:]\n",
    "\t\telse:\n",
    "\t\t\tword += token\n",
    "\t\t\n",
    "\t\tif word == (entire_word or \"[UNK]\") and word != sdata[1][-1]:\n",
    "\t\t\tword = \"\"\n",
    "\t\t\tentire_word = next(iterated_word)\n",
    "\t\t\tner = next(iterated_ner)\n",
    "\t\t\ttokenized_ner_list.append(ner)\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tif ner == \"O\":\n",
    "\t\t\t\ttokenized_ner_list.append(\"O\")\n",
    "\t\t\telse:\n",
    "\t\t\t\ttokenized_ner_list.append(\"I\" + ner[1:])\n",
    "\n",
    "\tprepro_sdata.append(sdata[0])\n",
    "\tprepro_sdata.append(morph_to_tokens)\n",
    "\tprepro_sdata.append(tokenized_ner_list)\n",
    "\n",
    "\t\n",
    "\tpreprodata.append(prepro_sdata)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa58cced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선방 한 정성룡 이 볼 을 걷 어 내 고 있 다 .\n",
      "['선', '##방', '한', '정', '##성', '##룡', '이', '볼', '을', '걷', '어', '내', '고', '있', '다', '.']\n",
      "['O', 'O', 'O', 'B-PS', 'I-PS', 'I-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "김학범 감독 이 장학영 에게 작전 지시 를 하 고 있 다 .\n",
      "['김', '##학', '##범', '감독', '이', '장', '##학', '##영', '에', '##게', '작', '##전', '지', '##시', '를', '하', '고', '있', '다', '.']\n",
      "['B-PS', 'I-PS', 'I-PS', 'O', 'O', 'B-PS', 'I-PS', 'I-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "\n",
      "호지슨 감독 은 올해 초 설기현 과 말싸움 을 벌였 다 .\n",
      "['호', '##지', '##슨', '감독', '은', '올', '##해', '초', '설', '##기', '##현', '과', '말', '##싸', '##움', '을', '벌', '##였', '다', '.']\n",
      "['B-PS', 'I-PS', 'I-PS', 'O', 'O', 'B-DT', 'I-DT', 'I-DT', 'B-PS', 'I-PS', 'I-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(preprodata[0][0])\n",
    "print(preprodata[0][1])\n",
    "print(preprodata[0][2])\n",
    "print(\"\\n\")\n",
    "print(preprodata[1][0])\n",
    "print(preprodata[1][1])\n",
    "print(preprodata[1][2])\n",
    "print(\"\\n\")\n",
    "print(preprodata[191][0])\n",
    "print(preprodata[191][1])\n",
    "print(preprodata[191][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "772c60a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro_file_name = 'prepro_' + file_name.rsplit('.')[0]\n",
    "PATH_preprodata = os.path.join(PATH_dir, prepro_file_name + '.json')\n",
    "\n",
    "with open(PATH_preprodata, 'w') as f:\n",
    "    json.dump(preprodata, f, ensure_ascii=False, indent='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f8c51a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f33169e",
   "metadata": {},
   "source": [
    "**Tag List**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a9f2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro_tag_list = []\n",
    "PATH_preprodata_tag_list = os.path.join(PATH_dir, prepro_file_name + '_tag_list.json')\n",
    "\n",
    "with open(PATH_preprodata_tag_list, 'w') as f:\n",
    "\n",
    "\tfor prepro_sdata in preprodata:\n",
    "\t\tprepro_tag_list.extend(prepro_sdata[2])\n",
    "\t\n",
    "\tprepro_tag_list = list(set(prepro_tag_list))\n",
    "\n",
    "\tjson.dump(prepro_tag_list, f, ensure_ascii=False, indent='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749d679e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce367b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prepro_tag_cnt_dict = {}\n",
    "\n",
    "# for tag in prepro_tag_extend_list:\n",
    "# \ttry: prepro_tag_cnt_dict[tag] += 1\n",
    "# \texcept: prepro_tag_cnt_dict[tag] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c402e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca1672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
